# === å¿…è¦å¯¼å…¥ ===
import os
import torch
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader
from retrieval_net import SFDH_FGIR
from hash_patch_dataset import get_dataloader
import config_hash as cfg


def hamming_distance(query, database):
    """
    è®¡ç®— query ä¸æ•°æ®åº“æ‰€æœ‰ hash å‘é‡çš„æ±‰æ˜è·ç¦»
    :param query: å•ä¸ªäºŒå€¼å“ˆå¸Œå‘é‡ (hash_bits,)
    :param database: å¤šä¸ªå“ˆå¸Œç  (N, hash_bits)
    :return: æ±‰æ˜è·ç¦» (N,)
    """
    return (query != database).sum(dim=1)


def visualize_topk(query_img, query_label, db_imgs, db_labels, db_codes, model, class_names, save_path, topk=5):
    """
    å¯è§†åŒ–Top-Kæ£€ç´¢ç»“æœ
    """
    plt.figure(figsize=(15, 3))
    
    # æ˜¾ç¤ºæŸ¥è¯¢å›¾åƒ
    plt.subplot(1, topk + 1, 1)
    plt.imshow(denormalize(query_img.permute(1, 2, 0).cpu()))
    plt.title(f'Query\n{class_names[query_label]}')
    plt.axis('off')
    
    # è®¡ç®—è·ç¦»å¹¶è·å–Top-K
    with torch.no_grad():
        query_code, _ = model(query_img.unsqueeze(0).to(next(model.parameters()).device))
        query_code = (query_code > 0).float().cpu()
    
    dist = hamming_distance(query_code.squeeze(0), db_codes)
    topk_idx = torch.topk(-dist, k=topk).indices
    
    # æ˜¾ç¤ºæ£€ç´¢ç»“æœ
    for i, idx in enumerate(topk_idx):
        plt.subplot(1, topk + 1, i + 2)
        plt.imshow(denormalize(db_imgs[idx].permute(1, 2, 0).cpu()))
        pred_label = db_labels[idx].item()
        plt.title(f'#{i+1}\n{class_names[pred_label]}')
        plt.axis('off')
    
    plt.tight_layout()
    plt.savefig(save_path)
    plt.close()


def compute_map(query_codes, query_labels, db_codes, db_labels, topk=None):
    """
    è®¡ç®—æ‰€æœ‰æŸ¥è¯¢çš„ mean Average Precision
    :param query_codes: æŸ¥è¯¢å“ˆå¸Œç é›†åˆ
    :param query_labels: æŸ¥è¯¢æ ‡ç­¾é›†åˆ
    :param db_codes: æ•°æ®åº“å“ˆå¸Œç é›†åˆ
    :param db_labels: æ•°æ®åº“æ ‡ç­¾é›†åˆ
    :param topk: åªåœ¨Top-Kæ’åºå†…è¯„ä¼°
    :return: mAP score
    """
    mAP = 0
    query_codes = query_codes.bool()
    db_codes = db_codes.bool()

    for i in range(len(query_codes)):
        query = query_codes[i]
        query_label = query_labels[i]

        dists = hamming_distance(query, db_codes)
        sorted_idxs = torch.argsort(dists)  # è¶Šç›¸ä¼¼è¶Šå‰

        if topk:
            sorted_idxs = sorted_idxs[:topk]

        correct = (db_labels[sorted_idxs] == query_label).float()

        if correct.sum() == 0:
            continue  # æ²¡æœ‰ç›¸å…³æ ·æœ¬ï¼Œè·³è¿‡è¯¥æŸ¥è¯¢

        ranks = torch.arange(1, len(correct) + 1).float()
        precision_at_k = torch.cumsum(correct, dim=0) / ranks
        AP = (precision_at_k * correct).sum() / correct.sum()  # Average Precision
        mAP += AP.item()

    return mAP / len(query_codes)


def denormalize(tensor):
    """
    å°† [-1, 1] åŒºé—´çš„å¼ é‡è¿˜åŸåˆ° [0, 1]ï¼Œé€‚åˆ matplotlib æ˜¾ç¤º
    """
    return (tensor * 0.5 + 0.5).clamp(0, 1)


def main():
    device = torch.device(cfg.device if torch.cuda.is_available() else 'cpu')
    print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡: {device}")

    # åŠ è½½æ¨¡å‹å¹¶æ¢å¤æƒé‡
    model = SFDH_FGIR(hash_bits=cfg.hash_bits, num_classes=3).to(device)
    checkpoint = torch.load(os.path.join(cfg.checkpoint_dir, 'best_model.pth'), map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼éªŒè¯å‡†ç¡®ç‡: {checkpoint['val_acc']*100:.2f}%")

    # åŠ è½½è®­ç»ƒé›†ï¼ˆç”¨äºå»ºåº“ï¼‰å’Œæµ‹è¯•é›†ï¼ˆç”¨äºæŸ¥è¯¢ï¼‰
    train_loader, class_names = get_dataloader(cfg.train_data, batch_size=cfg.batch_size, transform_type='val')
    test_loader, _ = get_dataloader(cfg.test_data, batch_size=1, transform_type='val')
    print(f"ğŸ“Š ç±»åˆ«: {class_names}")

    # æå–è®­ç»ƒé›†å“ˆå¸Œæ•°æ®åº“
    print("ğŸ” æ„å»ºå“ˆå¸Œæ•°æ®åº“...")
    db_imgs, db_labels, db_codes = [], [], []
    with torch.no_grad():
        for imgs, labels in train_loader:
            imgs = imgs.to(device)
            hash_codes, _ = model(imgs)
            db_imgs.extend(imgs.cpu())
            db_labels.extend(labels.cpu())
            db_codes.append((hash_codes > 0).float().cpu())

    db_codes = torch.cat(db_codes)
    db_labels = torch.tensor(db_labels)
    print(f"âœ… æ•°æ®åº“æ„å»ºå®Œæˆï¼å…± {len(db_codes)} ä¸ªæ ·æœ¬")

    # åˆå§‹åŒ–ç»Ÿè®¡
    top1_correct, topk_correct = 0, 0
    query_hashes, query_labels = [], []
    total = 0

    # éå†æµ‹è¯•é›†åšæ£€ç´¢è¯„ä¼°
    print("\nğŸ” å¼€å§‹æ£€ç´¢è¯„ä¼°...")
    os.makedirs('./results/visualization_topk', exist_ok=True)
    
    for i, (img, label) in enumerate(test_loader):
        img = img[0]
        label = label[0].item()

        with torch.no_grad():
            query_code, _ = model(img.unsqueeze(0).to(device))
            query_code = (query_code > 0).float().cpu()

        dist = hamming_distance(query_code.squeeze(0), db_codes)
        topk_idx = torch.topk(-dist, k=cfg.top_k).indices
        retrieved_labels = [db_labels[i].item() for i in topk_idx]

        # Top-Kç»Ÿè®¡
        top1_correct += int(retrieved_labels[0] == label)
        topk_correct += int(label in retrieved_labels)

        query_hashes.append(query_code.squeeze(0))
        query_labels.append(label)
        total += 1

        # ä¿å­˜å¯è§†åŒ–å›¾åƒ
        save_path = f'./results/visualization_topk/query_{i:04d}_{class_names[label]}.png'
        visualize_topk(img, label, db_imgs, db_labels, db_codes, model, class_names, save_path, topk=cfg.top_k)

    # æ‹¼æ¥æ‰€æœ‰æŸ¥è¯¢ç å’Œæ ‡ç­¾
    query_hashes = torch.stack(query_hashes)
    query_labels = torch.tensor(query_labels)

    # è®¡ç®—mAP
    map_score = compute_map(query_hashes, query_labels, db_codes, db_labels, topk=cfg.map_top_k)

    # æ‰“å°æœ€ç»ˆç»“æœ
    print("\nğŸ“Š æ£€ç´¢è¯„ä¼°ç»“æœï¼š")
    print(f"Top-1 Accuracy: {top1_correct / total * 100:.2f}%")
    print(f"Top-{cfg.top_k} Accuracy: {topk_correct / total * 100:.2f}%")
    print(f"mAP@{cfg.map_top_k}: {map_score * 100:.2f}%")
    print(f"\nâœ… è¯„ä¼°å®Œæˆï¼å¯è§†åŒ–ç»“æœä¿å­˜åœ¨ ./results/visualization_topk/ ç›®å½•ä¸‹")


if __name__ == '__main__':
    main()
