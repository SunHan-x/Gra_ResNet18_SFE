# === å¿…è¦å¯¼å…¥ ===
import os
import torch
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader
from retrieval_net import RetrievalNet
from hash_patch_dataset import get_dataloader
import config_hash as cfg


def hamming_distance(query, database):
    """
    è®¡ç®— query ä¸æ•°æ®åº“æ‰€æœ‰ hash å‘é‡çš„æ±‰æ˜è·ç¦»
    :param query: å•ä¸ªäºŒå€¼å“ˆå¸Œå‘é‡ (hash_bits,)
    :param database: å¤šä¸ªå“ˆå¸Œç  (N, hash_bits)
    :return: æ±‰æ˜è·ç¦» (N,)
    """
    return (query != database).sum(dim=1)


def visualize_topk(query_img, query_label, db_imgs, db_labels, db_codes, model, class_names, save_path, topk=5):
    """
    ç”Ÿæˆå¹¶ä¿å­˜Top-Kå›¾åƒæ£€ç´¢ç»“æœå›¾
    :param query_img: æŸ¥è¯¢å›¾åƒå¼ é‡
    :param query_label: æŸ¥è¯¢æ ‡ç­¾
    :param db_imgs, db_labels, db_codes: æ•°æ®åº“å›¾åƒã€æ ‡ç­¾ã€å“ˆå¸Œç 
    :param model: å“ˆå¸Œæ¨¡å‹
    :param class_names: ç±»åˆ«ååˆ—è¡¨
    :param save_path: å›¾åƒä¿å­˜è·¯å¾„
    :param topk: å±•ç¤ºå‰Kä¸ªæ£€ç´¢ç»“æœ
    """
    model.eval()
    with torch.no_grad():
        img = query_img.unsqueeze(0).to(cfg.device)
        query_code, _ = model(img)
        query_code = (query_code > 0).float().cpu()

    dist = hamming_distance(query_code.squeeze(0), db_codes)
    topk_idx = torch.topk(-dist, topk).indices  # æ’åºè·ç¦»æœ€å°ï¼ˆæœ€ç›¸ä¼¼ï¼‰

    retrieved_imgs = [db_imgs[i] for i in topk_idx]
    retrieved_labels = [db_labels[i].item() for i in topk_idx]

    # å¯è§†åŒ–ç»˜å›¾
    plt.figure(figsize=(16, 4))
    plt.subplot(1, topk + 1, 1)
    plt.imshow(query_img.permute(1, 2, 0))
    plt.title(f'Query\n{class_names[query_label]}', color='blue')
    plt.axis('off')

    for i in range(topk):
        plt.subplot(1, topk + 1, i + 2)
        plt.imshow(retrieved_imgs[i].permute(1, 2, 0))
        color = 'green' if retrieved_labels[i] == query_label else 'red'
        plt.title(f'Top-{i+1}\n{class_names[retrieved_labels[i]]}', color=color)
        plt.axis('off')

    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    plt.tight_layout()
    plt.savefig(save_path, dpi=300)
    plt.close()


def compute_map(query_codes, query_labels, db_codes, db_labels, topk=None):
    """
    è®¡ç®—æ‰€æœ‰æŸ¥è¯¢çš„ mean Average Precision
    :param query_codes: æŸ¥è¯¢å“ˆå¸Œç é›†åˆ
    :param query_labels: æŸ¥è¯¢æ ‡ç­¾é›†åˆ
    :param db_codes: æ•°æ®åº“å“ˆå¸Œç é›†åˆ
    :param db_labels: æ•°æ®åº“æ ‡ç­¾é›†åˆ
    :param topk: åªåœ¨Top-Kæ’åºå†…è¯„ä¼°
    :return: mAP score
    """
    mAP = 0
    query_codes = query_codes.bool()
    db_codes = db_codes.bool()

    for i in range(len(query_codes)):
        query = query_codes[i]
        query_label = query_labels[i]

        dists = hamming_distance(query, db_codes)
        sorted_idxs = torch.argsort(dists)  # è¶Šç›¸ä¼¼è¶Šå‰

        if topk:
            sorted_idxs = sorted_idxs[:topk]

        correct = (db_labels[sorted_idxs] == query_label).float()

        if correct.sum() == 0:
            continue  # æ²¡æœ‰ç›¸å…³æ ·æœ¬ï¼Œè·³è¿‡è¯¥æŸ¥è¯¢

        ranks = torch.arange(1, len(correct) + 1).float()
        precision_at_k = torch.cumsum(correct, dim=0) / ranks
        AP = (precision_at_k * correct).sum() / correct.sum()  # Average Precision
        mAP += AP.item()

    return mAP / len(query_codes)


def main():
    device = torch.device(cfg.device if torch.cuda.is_available() else 'cpu')

    # åŠ è½½æ¨¡å‹å¹¶æ¢å¤æƒé‡
    model = RetrievalNet(hash_bits=cfg.hash_bits, num_classes=3).to(device)
    model.load_state_dict(torch.load(os.path.join(cfg.checkpoint_dir, 'best_hash_model.pth'), map_location=device))
    model.eval()

    # åŠ è½½è®­ç»ƒé›†ï¼ˆç”¨äºå»ºåº“ï¼‰å’Œæµ‹è¯•é›†ï¼ˆç”¨äºæŸ¥è¯¢ï¼‰
    train_loader, class_names = get_dataloader(cfg.train_data, batch_size=cfg.batch_size, transform_type='val')
    test_loader, _ = get_dataloader(cfg.test_data, batch_size=1, transform_type='val')

    # æå–è®­ç»ƒé›†å“ˆå¸Œæ•°æ®åº“
    db_imgs, db_labels, db_codes = [], [], []
    with torch.no_grad():
        for imgs, labels in train_loader:
            imgs = imgs.to(device)
            hash_codes, _ = model(imgs)
            db_imgs.extend(imgs.cpu())
            db_labels.extend(labels.cpu())
            db_codes.append((hash_codes > 0).float().cpu())

    db_codes = torch.cat(db_codes)
    db_labels = torch.tensor(db_labels)

    # åˆå§‹åŒ–ç»Ÿè®¡
    top1_correct, top5_correct = 0, 0
    query_hashes, query_labels = [], []
    total = 0

    # éå†æµ‹è¯•é›†åšæ£€ç´¢è¯„ä¼°
    for i, (img, label) in enumerate(test_loader):
        img = img[0]
        label = label[0].item()

        with torch.no_grad():
            query_code, _ = model(img.unsqueeze(0).to(device))
            query_code = (query_code > 0).float().cpu()

        dist = hamming_distance(query_code.squeeze(0), db_codes)
        topk_idx = torch.topk(-dist, k=5).indices
        retrieved_labels = [db_labels[i].item() for i in topk_idx]

        # Top-Kç»Ÿè®¡
        top1_correct += int(retrieved_labels[0] == label)
        top5_correct += int(label in retrieved_labels)

        query_hashes.append(query_code.squeeze(0))
        query_labels.append(label)
        total += 1

        # ä¿å­˜å¯è§†åŒ–å›¾åƒ
        save_path = f'./results/visualization_topk/query_{i:04d}_{class_names[label]}.png'
        visualize_topk(img, label, db_imgs, db_labels, db_codes, model, class_names, save_path, topk=5)

    # æ‹¼æ¥æ‰€æœ‰æŸ¥è¯¢ç å’Œæ ‡ç­¾
    query_hashes = torch.stack(query_hashes)
    query_labels = torch.tensor(query_labels)

    # è®¡ç®—mAP
    map_score = compute_map(query_hashes, query_labels, db_codes, db_labels, topk=100)

    # æ‰“å°æœ€ç»ˆç»“æœ
    print("\nğŸ“Š æ£€ç´¢è¯„ä¼°ç»“æœï¼š")
    print(f"Top-1 Accuracy: {top1_correct / total * 100:.2f}%")
    print(f"Top-5 Accuracy: {top5_correct / total * 100:.2f}%")
    print(f"mAP@100       : {map_score * 100:.2f}%")


if __name__ == '__main__':
    main()
